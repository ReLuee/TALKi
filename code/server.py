# server.py
from queue import Queue, Empty
import logging
from logsetup import setup_logging
setup_logging(logging.INFO)
logger = logging.getLogger(__name__)
if __name__ == "__main__":
    logger.info("ğŸ–¥ï¸ğŸ‘‹ ë¡œì»¬ ì‹¤ì‹œê°„ ìŒì„± ì±„íŒ…ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤")

from upsample_overlap import UpsampleOverlap
from datetime import datetime
from colors import Colors
import uvicorn
import asyncio
import struct
import json
import time
import threading # SpeechPipelineManager ë‚´ë¶€ ë° AbortWorkerë¥¼ ìœ„í•´ ìŠ¤ë ˆë”© ìœ ì§€
import sys
import os # í™˜ê²½ ë³€ìˆ˜ ì ‘ê·¼ì„ ìœ„í•´ ì¶”ê°€

from typing import Any, Dict, Optional, Callable # docstringì˜ íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•´ ì¶”ê°€
from contextlib import asynccontextmanager

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from starlette.responses import HTMLResponse, Response, FileResponse

USE_SSL = True
# TTS_START_ENGINE = "orpheus"
# TTS_START_ENGINE = "kokoro"
TTS_START_ENGINE = "coqui"
# TTS_START_ENGINE = "elabs"
# TTS_ORPHEUS_MODEL = "Orpheus_3B-1BaseGGUF/mOrpheus_3B-1Base_Q4_K_M.gguf"
TTS_ORPHEUS_MODEL = "orpheus-3b-0.1-ft-Q8_0-GGUF/orpheus-3b-0.1-ft-q8_0.gguf"

LLM_START_PROVIDER = "openai"
LLM_START_MODEL = "gpt-4o"
# LLM_START_MODEL = "qwen3:30b-a3b"
# LLM_START_MODEL = "hf.co/bartowski/huihui-ai_Mistral-Small-24B-Instruct-2501-abliterated-GGUF:Q4_K_M"
# LLM_START_PROVIDER = "lmstudio"
# LLM_START_MODEL = "Qwen3-30B-A3B-GGUF/Qwen3-30B-A3B-Q3_K_L.gguf"
NO_THINK = False
DIRECT_STREAM = TTS_START_ENGINE=="orpheus"

if __name__ == "__main__":
    logger.info(f"ğŸ–¥ï¸âš™ï¸ {Colors.apply('[íŒŒë¼ë¯¸í„°]').blue} ì‹œì‘ ì—”ì§„: {Colors.apply(TTS_START_ENGINE).blue}")
    logger.info(f"ğŸ–¥ï¸âš™ï¸ {Colors.apply('[íŒŒë¼ë¯¸í„°]').blue} ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë°: {Colors.apply('ì¼œì§' if DIRECT_STREAM else 'êº¼ì§').blue}")

# ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ íì— í—ˆìš©ë˜ëŠ” ìµœëŒ€ í¬ê¸° ì •ì˜
try:
    MAX_AUDIO_QUEUE_SIZE = int(os.getenv("MAX_AUDIO_QUEUE_SIZE", 50))
    if __name__ == "__main__":
        logger.info(f"ğŸ–¥ï¸âš™ï¸ {Colors.apply('[íŒŒë¼ë¯¸í„°]').blue} ì˜¤ë””ì˜¤ í í¬ê¸° ì œí•œ ì„¤ì •: {Colors.apply(str(MAX_AUDIO_QUEUE_SIZE)).blue}")
except ValueError:
    if __name__ == "__main__":
        logger.warning("ğŸ–¥ï¸âš ï¸ ì˜ëª»ëœ MAX_AUDIO_QUEUE_SIZE í™˜ê²½ ë³€ìˆ˜. ê¸°ë³¸ê°’ ì‚¬ìš©: 50")
    MAX_AUDIO_QUEUE_SIZE = 50


if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

#from handlerequests import LanguageProcessor
#from audio_out import AudioOutProcessor
from audio_in import AudioInputProcessor
from speech_pipeline_manager import SpeechPipelineManager
from colors import Colors

LANGUAGE = "en"
# TTS_FINAL_TIMEOUT = 0.5 # ì•ˆì •ì„±ì„ ìœ„í•´ 1.0ì´ í•„ìš”í•œì§€ ë¶ˆí™•ì‹¤
TTS_FINAL_TIMEOUT = 1.0 # ì•ˆì •ì„±ì„ ìœ„í•´ 1.0ì´ í•„ìš”í•œì§€ ë¶ˆí™•ì‹¤

# --------------------------------------------------------------------
# ì»¤ìŠ¤í…€ ìºì‹œ ì—†ìŒ StaticFiles
# --------------------------------------------------------------------
class NoCacheStaticFiles(StaticFiles):
    """
    í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìºì‹±ì„ í—ˆìš©í•˜ì§€ ì•Šê³  ì •ì  íŒŒì¼ì„ ì œê³µí•©ë‹ˆë‹¤.

    ë¸Œë¼ìš°ì €ê°€ ì •ì  ìì‚°ì„ ìºì‹±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” 'Cache-Control' í—¤ë”ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´
    ê¸°ë³¸ Starlette StaticFilesë¥¼ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤. ê°œë°œì— ìœ ìš©í•©ë‹ˆë‹¤.
    """
    async def get_response(self, path: str, scope: Dict[str, Any]) -> Response:
        """
        ìš”ì²­ëœ ê²½ë¡œì— ëŒ€í•œ ì‘ë‹µì„ ê°€ì ¸ì˜¤ê³  ìºì‹œ ì—†ìŒ í—¤ë”ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

        Args:
            path: ìš”ì²­ëœ ì •ì  íŒŒì¼ì˜ ê²½ë¡œ.
            scope: ìš”ì²­ì— ëŒ€í•œ ASGI ìŠ¤ì½”í”„ ë”•ì…”ë„ˆë¦¬.

        Returns:
            ìºì‹œ ì œì–´ í—¤ë”ê°€ ìˆ˜ì •ëœ Starlette ì‘ë‹µ ê°ì²´.
        """
        response: Response = await super().get_response(path, scope)
        response.headers["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
        # no-storeì™€ í•¨ê»˜ ë°˜ë“œì‹œ í•„ìš”í•œ ê²ƒì€ ì•„ë‹ ìˆ˜ ìˆì§€ë§Œ, ë§Œì¼ì„ ëŒ€ë¹„í•¨
        if "etag" in response.headers:
             response.headers.__delitem__("etag")
        if "last-modified" in response.headers:
             response.headers.__delitem__("last-modified")
        return response

# --------------------------------------------------------------------
# ë¼ì´í”„ìŠ¤íŒ¬ ê´€ë¦¬
# --------------------------------------------------------------------
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¼ì´í”„ìŠ¤íŒ¬ì„ ê´€ë¦¬í•˜ë©°, ë¦¬ì†ŒìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤.

    SpeechPipelineManager, Upsampler, AudioInputProcessorì™€ ê°™ì€ ì „ì—­ ì»´í¬ë„ŒíŠ¸ë¥¼
    ì´ˆê¸°í™”í•˜ê³  `app.state`ì— ì €ì¥í•©ë‹ˆë‹¤. ì¢…ë£Œ ì‹œ ì •ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        app: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤.
    """
    logger.info("ğŸ–¥ï¸â–¶ï¸ ì„œë²„ ì‹œì‘ ì¤‘")
    # ì „ì—­ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”, ì—°ê²°ë³„ ìƒíƒœ ì•„ë‹˜
    app.state.SpeechPipelineManager = SpeechPipelineManager(
        tts_engine=TTS_START_ENGINE,
        llm_provider=LLM_START_PROVIDER,
        llm_model=LLM_START_MODEL,
        no_think=NO_THINK,
        orpheus_model=TTS_ORPHEUS_MODEL,
    )

    app.state.Upsampler = UpsampleOverlap()
    app.state.AudioInputProcessor = AudioInputProcessor(
        LANGUAGE,
        is_orpheus=TTS_START_ENGINE=="orpheus",
        on_prolonged_silence_callback=app.state.SpeechPipelineManager.handle_prolonged_silence,
        pipeline_latency=app.state.SpeechPipelineManager.full_output_pipeline_latency / 1000, # ì´ˆ ë‹¨ìœ„
    )
    app.state.Aborting = False # ì´ê²ƒì„ ìœ ì§€í• ê¹Œ? ì œê³µëœ ìŠ¤ë‹ˆí«ì—ì„œ ì‚¬ìš©ë²•ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ. ë³€ê²½ ìµœì†Œí™”.

    yield

    logger.info("ğŸ–¥ï¸â¹ï¸ ì„œë²„ ì¢…ë£Œ ì¤‘")
    app.state.AudioInputProcessor.shutdown()
    app.state.SpeechPipelineManager.shutdown()


# --------------------------------------------------------------------
# FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤
# --------------------------------------------------------------------
app = FastAPI(lifespan=lifespan)

# í•„ìš”í•œ ê²½ìš° CORS í™œì„±í™”
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìºì‹œ ì—†ì´ ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸
app.mount("/static", NoCacheStaticFiles(directory="static"), name="static")

@app.get("/favicon.ico")
async def favicon():
    """
    favicon.ico íŒŒì¼ì„ ì œê³µí•©ë‹ˆë‹¤.

    Returns:
        íŒŒë¹„ì½˜ì„ í¬í•¨í•˜ëŠ” FileResponse.
    """
    return FileResponse("static/favicon.ico")

@app.get("/")
async def get_index() -> HTMLResponse:
    """
    ë©”ì¸ index.html í˜ì´ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

    static/index.htmlì˜ ë‚´ìš©ì„ ì½ì–´ HTML ì‘ë‹µìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        index.htmlì˜ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ” HTMLResponse.
    """
    with open("static/index.html", "r", encoding="utf-8") as f:
        html_content = f.read()
    return HTMLResponse(content=html_content)

# --------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# --------------------------------------------------------------------
def parse_json_message(text: str) -> dict:
    """
    JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•©ë‹ˆë‹¤.

    JSONì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³ ë¥¼ ê¸°ë¡í•˜ê³  ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        text: íŒŒì‹±í•  JSON ë¬¸ìì—´.

    Returns:
        íŒŒì‹±ëœ JSONì„ ë‚˜íƒ€ë‚´ëŠ” ë”•ì…”ë„ˆë¦¬, ë˜ëŠ” ì˜¤ë¥˜ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬.
    """
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        logger.warning("ğŸ–¥ï¸âš ï¸ ì˜ëª»ëœ JSON í˜•ì‹ì˜ í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
        return {}

def format_timestamp_ns(timestamp_ns: int) -> str:
    """
    ë‚˜ë…¸ì´ˆ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” HH:MM:SS.fff ë¬¸ìì—´ë¡œ í¬ë§·í•©ë‹ˆë‹¤.

    Args:
        timestamp_ns: ì—í¬í¬ ì´í›„ì˜ ë‚˜ë…¸ì´ˆ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„.

    Returns:
        ì‹œê°„:ë¶„:ì´ˆ.ë°€ë¦¬ì´ˆ í˜•ì‹ì˜ ë¬¸ìì—´.
    """
    # ì „ì²´ ì´ˆì™€ ë‚˜ë…¸ì´ˆ ë‚˜ë¨¸ì§€ë¡œ ë¶„ë¦¬
    seconds = timestamp_ns // 1_000_000_000
    remainder_ns = timestamp_ns % 1_000_000_000

    # ì´ˆ ë¶€ë¶„ì„ datetime ê°ì²´ë¡œ ë³€í™˜ (ë¡œì»¬ ì‹œê°„)
    dt = datetime.fromtimestamp(seconds)

    # ì£¼ ì‹œê°„ì„ HH:MM:SSë¡œ í¬ë§·
    time_str = dt.strftime("%H:%M:%S")

    # ì˜ˆë¥¼ ë“¤ì–´, ë°€ë¦¬ì´ˆë¥¼ ì›í•˜ë©´ ë‚˜ë¨¸ì§€ë¥¼ 1e6ìœ¼ë¡œ ë‚˜ëˆ„ê³  3ìë¦¬ë¡œ í¬ë§·
    milliseconds = remainder_ns // 1_000_000
    formatted_timestamp = f"{time_str}.{milliseconds:03d}"

    return formatted_timestamp

# --------------------------------------------------------------------
# ì›¹ì†Œì¼“ ë°ì´í„° ì²˜ë¦¬
# --------------------------------------------------------------------

async def process_incoming_data(ws: WebSocket, app: FastAPI, incoming_chunks: asyncio.Queue, callbacks: 'TranscriptionCallbacks') -> None:
    """
    ì›¹ì†Œì¼“ì„ í†µí•´ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ê³ , ì˜¤ë””ì˜¤ ë° í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ê³ , ë©”íƒ€ë°ì´í„°(íƒ€ì„ìŠ¤íƒ¬í”„, í”Œë˜ê·¸)ë¥¼ ì¶”ì¶œí•˜ì—¬
    ì˜¤ë””ì˜¤ PCM ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ `incoming_chunks` íì— ë„£ìŠµë‹ˆë‹¤.
    íê°€ ê°€ë“ ì°¨ë©´ ì—­ì••ë ¥(back-pressure)ì„ ì ìš©í•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ ë©”ì‹œì§€(JSONìœ¼ë¡œ ê°€ì •)ë¥¼ íŒŒì‹±í•˜ê³  ë©”ì‹œì§€ ìœ í˜•ì— ë”°ë¼ ì‘ì—…ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤
    (ì˜ˆ: `callbacks`ë¥¼ í†µí•´ í´ë¼ì´ì–¸íŠ¸ TTS ìƒíƒœ ì—…ë°ì´íŠ¸, ê¸°ë¡ ì§€ìš°ê¸°, ì†ë„ ì„¤ì •).

    Args:
        ws: ì›¹ì†Œì¼“ ì—°ê²° ì¸ìŠ¤í„´ìŠ¤.
        app: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ (í•„ìš” ì‹œ ì „ì—­ ìƒíƒœì— ì ‘ê·¼í•˜ê¸° ìœ„í•¨).
        incoming_chunks: ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ë¥¼ ë„£ì„ asyncio í.
        callbacks: ì´ ì—°ê²°ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” TranscriptionCallbacks ì¸ìŠ¤í„´ìŠ¤.
    """
    try:
        while True:
            msg = await ws.receive()
            if "bytes" in msg and msg["bytes"]:
                raw = msg["bytes"]
                logger.debug(f"ğŸ–¥ï¸ğŸ”Š ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(raw)} ë°”ì´íŠ¸") # STT ì§„ë‹¨ ë¡œê·¸ 1

                # ìµœì†Œ 8ë°”ì´íŠ¸ í—¤ë” í™•ì¸: 4ë°”ì´íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„(ms) + 4ë°”ì´íŠ¸ í”Œë˜ê·¸
                if len(raw) < 8:
                    logger.warning("ğŸ–¥ï¸âš ï¸ 8ë°”ì´íŠ¸ í—¤ë”ë³´ë‹¤ ì§§ì€ íŒ¨í‚·ì„ ìˆ˜ì‹ í–ˆìŠµë‹ˆë‹¤.")
                    continue

                # ë¹…ì—”ë””ì•ˆ uint32 íƒ€ì„ìŠ¤íƒ¬í”„(ms)ì™€ uint32 í”Œë˜ê·¸ ì–¸íŒ¨í‚¹
                timestamp_ms, flags = struct.unpack("!II", raw[:8])
                client_sent_ns = timestamp_ms * 1_000_000

                # ê³ ì • í•„ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    "client_sent_ms":           timestamp_ms,
                    "client_sent":              client_sent_ns,
                    "client_sent_formatted":    format_timestamp_ns(client_sent_ns),
                    "isTTSPlaying":             bool(flags & 1),
                }

                # ì„œë²„ ìˆ˜ì‹  ì‹œê°„ ê¸°ë¡
                server_ns = time.time_ns()
                metadata["server_received"] = server_ns
                metadata["server_received_formatted"] = format_timestamp_ns(server_ns)

                # í˜ì´ë¡œë“œì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ì›ì‹œ PCM ë°”ì´íŠ¸
                metadata["pcm"] = raw[8:]

                # ë°ì´í„° ë„£ê¸° ì „ í í¬ê¸° í™•ì¸
                current_qsize = incoming_chunks.qsize()
                if current_qsize < MAX_AUDIO_QUEUE_SIZE:
                    # ì´ì œ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬(PCM ì˜¤ë””ì˜¤ í¬í•¨)ë§Œ ì²˜ë¦¬ íì— ë„£ìŒ.
                    await incoming_chunks.put(metadata)
                else:
                    # íê°€ ê°€ë“ ì°¸, ì²­í¬ë¥¼ ë²„ë¦¬ê³  ê²½ê³  ê¸°ë¡
                    logger.warning(
                        f"ğŸ–¥ï¸âš ï¸ ì˜¤ë””ì˜¤ íê°€ ê°€ë“ ì°¼ìŠµë‹ˆë‹¤ ({current_qsize}/{MAX_AUDIO_QUEUE_SIZE}); ì²­í¬ë¥¼ ë²„ë¦½ë‹ˆë‹¤. ì§€ì—°ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )

            elif "text" in msg and msg["text"]:
                # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©”ì‹œì§€: JSON íŒŒì‹±
                data = parse_json_message(msg["text"])
                msg_type = data.get("type")
                logger.info(Colors.apply(f"ğŸ–¥ï¸ğŸ“¥ â†â†í´ë¼ì´ì–¸íŠ¸: {data}").orange)


                if msg_type == "tts_start":
                    logger.info("ğŸ–¥ï¸â„¹ï¸ í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° tts_start ìˆ˜ì‹ .")
                    # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ ìƒíƒœ ì—…ë°ì´íŠ¸
                    callbacks.tts_client_playing = True
                elif msg_type == "tts_stop":
                    logger.info("ğŸ–¥ï¸â„¹ï¸ í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° tts_stop ìˆ˜ì‹ .")
                    # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ ìƒíƒœ ì—…ë°ì´íŠ¸
                    callbacks.tts_client_playing = False
                    # AI-to-AI ëŒ€í™” ì¤‘ì´ë©´ ë‹¤ìŒ í„´ ì‹œì‘ ì‹ í˜¸ ì „ì†¡
                    if app.state.SpeechPipelineManager.ai_to_ai_active:
                        callbacks.on_tts_playback_finished()
                    else:
                        # ì¼ë°˜ AI-ì‚¬ìš©ì ëŒ€í™”ì—ì„œëŠ” ì¹¨ë¬µ íƒ€ì´ë¨¸ ì‹œì‘
                        callbacks.start_silence_timer_after_tts_stop()
                # server.pyì˜ handleJSONMessage í•¨ìˆ˜ì— ì¶”ê°€
                elif msg_type == "clear_history":
                    logger.info("ğŸ–¥ï¸â„¹ï¸ í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° clear_history ìˆ˜ì‹ .")
                    app.state.SpeechPipelineManager.reset()
                elif msg_type == "set_speed":
                    speed_value = data.get("speed", 0)
                    speed_factor = speed_value / 100.0  # 0-100ì„ 0.0-1.0ìœ¼ë¡œ ë³€í™˜
                    turn_detection = app.state.AudioInputProcessor.transcriber.turn_detection
                    if turn_detection:
                        turn_detection.update_settings(speed_factor)
                        logger.info(f"ğŸ–¥ï¸âš™ï¸ ë°œí™” ì „í™˜ ê°ì§€ ì„¤ì •ì„ ê³„ìˆ˜ {speed_factor:.2f}(ìœ¼)ë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
                elif msg_type == "start_ai_conversation":
                    topic = data.get("topic", "a friendly chat about their day")
                    logger.info(f"ğŸ–¥ï¸ğŸ¤– í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° AI ëŒ€í™” ì‹œì‘ ìš”ì²­ ìˆ˜ì‹  (ì£¼ì œ: {topic})")
                    # ì´ ë¶€ë¶„ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ SpeechPipelineManagerì— í•´ë‹¹ ë©”ì„œë“œë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
                    if hasattr(app.state.SpeechPipelineManager, "start_ai_to_ai_conversation"):
                        app.state.SpeechPipelineManager.start_ai_to_ai_conversation(topic, manual_start=True)
                    else:
                        logger.warning("SpeechPipelineManagerì— 'start_ai_to_ai_conversation' ë©”ì„œë“œê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                elif msg_type == "toggle_ai_pause":
                    logger.info("ğŸ–¥ï¸â¯ï¸ í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° AI ëŒ€í™” ì¼ì‹œì¤‘ì§€/ì¬ê°œ ìš”ì²­ ìˆ˜ì‹ .")
                    callbacks.handle_toggle_ai_pause()


    except asyncio.CancelledError:
        pass # ì‘ì—… ì·¨ì†ŒëŠ” ì—°ê²° ëŠê¹€ ì‹œ ì˜ˆìƒë¨
    except WebSocketDisconnect as e:
        logger.warning(f"ğŸ–¥ï¸âš ï¸ {Colors.apply('ê²½ê³ ').red} process_incoming_dataì—ì„œ ì—°ê²° ëŠê¹€: {repr(e)}")
    except RuntimeError as e:  # ë‹«íŒ ì „ì†¡ì—ì„œ ìì£¼ ë°œìƒ
        logger.error(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ëŸ°íƒ€ì„ ì˜¤ë¥˜').red} process_incoming_dataì—ì„œ ë°œìƒ: {repr(e)}")
    except Exception as e:
        logger.exception(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ì˜ˆì™¸').red} process_incoming_dataì—ì„œ ë°œìƒ: {repr(e)}")

async def send_text_messages(ws: WebSocket, message_queue: asyncio.Queue) -> None:
    """
    íì—ì„œ í´ë¼ì´ì–¸íŠ¸ë¡œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì›¹ì†Œì¼“ì„ í†µí•´ ê³„ì† ì „ì†¡í•©ë‹ˆë‹¤.

    `message_queue`ì—ì„œ ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë¦¬ê³ , JSONìœ¼ë¡œ í¬ë§·í•˜ì—¬ ì—°ê²°ëœ
    ì›¹ì†Œì¼“ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•©ë‹ˆë‹¤. TTSê°€ ì•„ë‹Œ ë©”ì‹œì§€ë¥¼ ë¡œê·¸ì— ê¸°ë¡í•©ë‹ˆë‹¤.

    Args:
        ws: ì›¹ì†Œì¼“ ì—°ê²° ì¸ìŠ¤í„´ìŠ¤.
        message_queue: JSONìœ¼ë¡œ ì „ì†¡ë  ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•˜ëŠ” asyncio í.
    """
    try:
        while True:
            await asyncio.sleep(0.001) # ì œì–´ê¶Œ ì–‘ë³´
            data = await message_queue.get()
            msg_type = data.get("type")
            if msg_type not in ["tts_chunk", "partial_assistant_answer", "final_assistant_answer"]:
                logger.info(Colors.apply(f"ğŸ–¥ï¸ğŸ“¤ â†’â†’í´ë¼ì´ì–¸íŠ¸: {data}").orange)
            await ws.send_json(data)
    except asyncio.CancelledError:
        pass # ì‘ì—… ì·¨ì†ŒëŠ” ì—°ê²° ëŠê¹€ ì‹œ ì˜ˆìƒë¨
    except WebSocketDisconnect as e:
        logger.warning(f"ğŸ–¥ï¸âš ï¸ {Colors.apply('ê²½ê³ ').red} send_text_messagesì—ì„œ ì—°ê²° ëŠê¹€: {repr(e)}")
    except RuntimeError as e:
        logger.error(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ëŸ°íƒ€ì„ ì˜¤ë¥˜').red} send_text_messagesì—ì„œ ë°œìƒ: {repr(e)}")
    except Exception as e:
        logger.exception(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ì˜ˆì™¸').red} send_text_messagesì—ì„œ ë°œìƒ: {repr(e)}")

async def _reset_interrupt_flag_async(app: FastAPI, callbacks: 'TranscriptionCallbacks'):
    """
    ì§€ì—° í›„ ë§ˆì´í¬ ì¤‘ë‹¨ í”Œë˜ê·¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤ (ë¹„ë™ê¸° ë²„ì „).

    1ì´ˆ ê¸°ë‹¤ë¦° í›„, AudioInputProcessorê°€ ì—¬ì „íˆ ì¤‘ë‹¨ë¨ìœ¼ë¡œ í‘œì‹œë˜ì–´ ìˆëŠ”ì§€
    í™•ì¸í•©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ í”„ë¡œì„¸ì„œì™€ ì—°ê²°ë³„ ì½œë°± ì¸ìŠ¤í„´ìŠ¤ ëª¨ë‘ì—ì„œ
    í”Œë˜ê·¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.

    Args:
        app: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ (AudioInputProcessorì— ì ‘ê·¼í•˜ê¸° ìœ„í•¨).
        callbacks: ì—°ê²°ì— ëŒ€í•œ TranscriptionCallbacks ì¸ìŠ¤í„´ìŠ¤.
    """
    await asyncio.sleep(1)
    # AudioInputProcessor ìì²´ì˜ ì¤‘ë‹¨ ìƒíƒœ í™•ì¸
    if app.state.AudioInputProcessor.interrupted:
        logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ™ï¸ â–¶ï¸ ë§ˆì´í¬ ê³„ì†ë¨ (ë¹„ë™ê¸° ë¦¬ì…‹)').cyan}")
        app.state.AudioInputProcessor.interrupted = False
        # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ ì¤‘ë‹¨ ì‹œê°„ ë¦¬ì…‹
        callbacks.interruption_time = 0
        logger.info(Colors.apply("ğŸ–¥ï¸ğŸ™ï¸ TTS ì²­í¬ í›„ ì¤‘ë‹¨ í”Œë˜ê·¸ ë¦¬ì…‹ë¨ (ë¹„ë™ê¸°)").cyan)

# ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ: tts_stop ì‹ í˜¸ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½ë¨
# async def _start_silence_timer_after_delay_async(app: FastAPI, delay: float):
#     """
#     ì§€ì •ëœ ì‹œê°„(ì´ˆ)ë§Œí¼ ê¸°ë‹¤ë¦° í›„ ì¥ì‹œê°„ ì¹¨ë¬µ íƒ€ì´ë¨¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
#     """
#     await asyncio.sleep(delay)
#     logger.info(f"ğŸ–¥ï¸â° {delay:.2f}ì´ˆ ëŒ€ê¸° í›„, ì¥ì‹œê°„ ì¹¨ë¬µ íƒ€ì´ë¨¸ ì‹œì‘.")
#     app.state.AudioInputProcessor.transcriber.start_prolonged_silence_timer()


async def send_tts_chunks(app: FastAPI, message_queue: asyncio.Queue, callbacks: 'TranscriptionCallbacks') -> None:
    """
    SpeechPipelineManagerì—ì„œ í´ë¼ì´ì–¸íŠ¸ë¡œ TTS ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ê³„ì† ì „ì†¡í•©ë‹ˆë‹¤.

    í˜„ì¬ ìŒì„± ìƒì„± ìƒíƒœ(ìˆëŠ” ê²½ìš°)ì™€ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìƒíƒœ(`callbacks`ë¥¼ í†µí•´)ë¥¼
    ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. í™œì„± ìƒì„±ì˜ íì—ì„œ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ê²€ìƒ‰í•˜ê³ , ì—…ìƒ˜í”Œë§/ì¸ì½”ë”©í•˜ì—¬
    í´ë¼ì´ì–¸íŠ¸ë¡œ ê°€ëŠ” `message_queue`ì— ë„£ìŠµë‹ˆë‹¤. ìƒì„± ì¢…ë£Œ ë¡œì§ê³¼ ìƒíƒœ ë¦¬ì…‹ì„
    ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        app: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­ ì»´í¬ë„ŒíŠ¸ì— ì ‘ê·¼í•˜ê¸° ìœ„í•¨).
        message_queue: ë‚˜ê°€ëŠ” TTS ì²­í¬ ë©”ì‹œì§€ë¥¼ ë„£ì„ asyncio í.
        callbacks: ì´ ì—°ê²°ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” TranscriptionCallbacks ì¸ìŠ¤í„´ìŠ¤.
    """
    try:
        logger.info("ğŸ–¥ï¸ğŸ”Š TTS ì²­í¬ ì „ì†¡ê¸° ì‹œì‘")
        last_quick_answer_chunk = 0
        last_chunk_sent = 0
        prev_status = None

        while True:
            await asyncio.sleep(0.001) # ì œì–´ê¶Œ ì–‘ë³´

            # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ interruption_time ì‚¬ìš©
            if app.state.AudioInputProcessor.interrupted and callbacks.interruption_time and time.time() - callbacks.interruption_time > 2.0:
                app.state.AudioInputProcessor.interrupted = False
                callbacks.interruption_time = 0 # ì½œë°±ì„ í†µí•´ ë¦¬ì…‹
                logger.info(Colors.apply("ğŸ–¥ï¸ğŸ™ï¸ 2ì´ˆ í›„ ì¤‘ë‹¨ í”Œë˜ê·¸ ë¦¬ì…‹ë¨").cyan)

            is_tts_finished = app.state.SpeechPipelineManager.is_valid_gen() and app.state.SpeechPipelineManager.running_generation.audio_quick_finished

            def log_status():
                nonlocal prev_status
                last_quick_answer_chunk_decayed = (
                    last_quick_answer_chunk
                    and time.time() - last_quick_answer_chunk > TTS_FINAL_TIMEOUT
                    and time.time() - last_chunk_sent > TTS_FINAL_TIMEOUT
                )

                curr_status = (
                    # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ ìƒíƒœ ì ‘ê·¼
                    int(callbacks.tts_to_client),
                    int(callbacks.tts_client_playing),
                    int(callbacks.tts_chunk_sent),
                    1, # í”Œë ˆì´ìŠ¤í™€ë”?
                    int(callbacks.is_hot), # ì½œë°±ì—ì„œ
                    int(callbacks.synthesis_started), # ì½œë°±ì—ì„œ
                    int(app.state.SpeechPipelineManager.running_generation is not None), # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ
                    int(app.state.SpeechPipelineManager.is_valid_gen()), # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ
                    int(is_tts_finished), # ê³„ì‚°ëœ ì§€ì—­ ë³€ìˆ˜
                    int(app.state.AudioInputProcessor.interrupted) # ì…ë ¥ í”„ë¡œì„¸ì„œ ìƒíƒœ
                )

                if curr_status != prev_status:
                    status = Colors.apply("ğŸ–¥ï¸ğŸš¦ ìƒíƒœ ").red
                    logger.info(
                        f"{status} ToClient {curr_status[0]}, "
                        f"ttsClientON {curr_status[1]}, " # ëª…í™•ì„±ì„ ìœ„í•´ ì•½ê°„ ì´ë¦„ ë³€ê²½
                        f"ChunkSent {curr_status[2]}, "
                        f"hot {curr_status[4]}, synth {curr_status[5]}"
                        f" gen {curr_status[6]}"
                        f" valid {curr_status[7]}"
                        f" tts_q_fin {curr_status[8]}"
                        f" mic_inter {curr_status[9]}"
                    )
                    prev_status = curr_status

            # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ ìƒíƒœ ì‚¬ìš©
            if not callbacks.tts_to_client:
                await asyncio.sleep(0.001)
                log_status()
                continue

            if not app.state.SpeechPipelineManager.running_generation:
                await asyncio.sleep(0.001)
                log_status()
                continue

            if app.state.SpeechPipelineManager.running_generation.abortion_started:
                await asyncio.sleep(0.001)
                log_status()
                continue

            if not app.state.SpeechPipelineManager.running_generation.audio_quick_finished:
                app.state.SpeechPipelineManager.running_generation.tts_quick_allowed_event.set()

            if not app.state.SpeechPipelineManager.running_generation.quick_answer_first_chunk_ready:
                await asyncio.sleep(0.001)
                log_status()
                continue

            chunk = None
            try:
                chunk = app.state.SpeechPipelineManager.running_generation.audio_chunks.get_nowait()
                if chunk:
                    last_quick_answer_chunk = time.time()
            except Empty:
                final_expected = app.state.SpeechPipelineManager.running_generation.quick_answer_provided
                audio_final_finished = app.state.SpeechPipelineManager.running_generation.audio_final_finished

                if not final_expected or audio_final_finished:
                    logger.info("ğŸ–¥ï¸ğŸ TTS ì²­í¬ ì „ì†¡ ë° 'ì‚¬ìš©ì ìš”ì²­/ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ' ì‚¬ì´í´ ì™„ë£Œ.")
                    callbacks.send_final_assistant_answer() # ì½œë°± ë©”ì„œë“œ

                    # íƒ€ì´ë¨¸ ì‹œì‘ ì „ ì˜¤ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
                    total_audio_duration = app.state.SpeechPipelineManager.running_generation.total_audio_duration
                    
                    app.state.SpeechPipelineManager.running_generation = None

                    callbacks.tts_chunk_sent = False # ì½œë°±ì„ í†µí•´ ë¦¬ì…‹
                    callbacks.reset_state() # ì½œë°±ì„ í†µí•´ ì—°ê²° ìƒíƒœ ë¦¬ì…‹
                    
                    # ì¹¨ë¬µ íƒ€ì´ë¨¸ëŠ” ì´ì œ tts_stop ì‹ í˜¸ë¥¼ ë°›ì„ ë•Œ ì‹œì‘ë©ë‹ˆë‹¤.
                    # (ê¸°ì¡´ ì˜¤ë””ì˜¤ ê¸¸ì´ ê¸°ë°˜ íƒ€ì´ë¨¸ ë¡œì§ ì œê±°ë¨)

                await asyncio.sleep(0.001)
                log_status()
                continue

            base64_chunk = app.state.Upsampler.get_base64_chunk(chunk)
            message_queue.put_nowait({
                "type": "tts_chunk",
                "content": base64_chunk
            })
            last_chunk_sent = time.time()

            # ì½œë°±ì„ í†µí•´ ì—°ê²°ë³„ ìƒíƒœ ì‚¬ìš©
            if not callbacks.tts_chunk_sent:
                # ìŠ¤ë ˆë“œ ëŒ€ì‹  ë¹„ë™ê¸° í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©
                asyncio.create_task(_reset_interrupt_flag_async(app, callbacks))

            callbacks.tts_chunk_sent = True # ì½œë°±ì„ í†µí•´ ì„¤ì •

    except asyncio.CancelledError:
        pass # ì‘ì—… ì·¨ì†ŒëŠ” ì—°ê²° ëŠê¹€ ì‹œ ì˜ˆìƒë¨
    except WebSocketDisconnect as e:
        logger.warning(f"ğŸ–¥ï¸âš ï¸ {Colors.apply('ê²½ê³ ').red} send_tts_chunksì—ì„œ ì—°ê²° ëŠê¹€: {repr(e)}")
    except RuntimeError as e:
        logger.error(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ëŸ°íƒ€ì„ ì˜¤ë¥˜').red} send_tts_chunksì—ì„œ ë°œìƒ: {repr(e)}")
    except Exception as e:
        logger.exception(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ì˜ˆì™¸').red} send_tts_chunksì—ì„œ ë°œìƒ: {repr(e)}")


# --------------------------------------------------------------------
# ìŒì„± ì¸ì‹ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì½œë°± í´ë˜ìŠ¤
# --------------------------------------------------------------------
class TranscriptionCallbacks:
    """
    ë‹¨ì¼ ì›¹ì†Œì¼“ ì—°ê²°ì˜ ìŒì„± ì¸ì‹ ìˆ˜ëª… ì£¼ê¸°ì— ëŒ€í•œ ìƒíƒœ ë° ì½œë°±ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

    ì´ í´ë˜ìŠ¤ëŠ” ì—°ê²°ë³„ ìƒíƒœ í”Œë˜ê·¸(ì˜ˆ: TTS ìƒíƒœ, ì‚¬ìš©ì ì¤‘ë‹¨)ë¥¼ ë³´ìœ í•˜ê³ 
    `AudioInputProcessor` ë° `SpeechPipelineManager`ì— ì˜í•´ íŠ¸ë¦¬ê±°ë˜ëŠ” ì½œë°± ë©”ì„œë“œë¥¼
    êµ¬í˜„í•©ë‹ˆë‹¤. ì œê³µëœ `message_queue`ë¥¼ í†µí•´ í´ë¼ì´ì–¸íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ê³ 
    ì¤‘ë‹¨ ë° ìµœì¢… ë‹µë³€ ì „ë‹¬ê³¼ ê°™ì€ ìƒí˜¸ ì‘ìš© ë¡œì§ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    ë˜í•œ ë¶€ë¶„ ìŒì„± ì¸ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë‹¨ í™•ì¸ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìŠ¤ë ˆë“œ ì›Œì»¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """
    def __init__(self, app: FastAPI, message_queue: asyncio.Queue):
        """
        ì›¹ì†Œì¼“ ì—°ê²°ì„ ìœ„í•œ TranscriptionCallbacks ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            app: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­ ì»´í¬ë„ŒíŠ¸ì— ì ‘ê·¼í•˜ê¸° ìœ„í•¨).
            message_queue: í´ë¼ì´ì–¸íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ê¸° ìœ„í•œ asyncio í.
        """
        self.app = app
        self.message_queue = message_queue
        self.final_transcription = ""
        self.abort_text = ""
        self.last_abort_text = ""

        # ì—¬ê¸°ì— ì—°ê²°ë³„ ìƒíƒœ í”Œë˜ê·¸ ì´ˆê¸°í™”
        self.tts_to_client: bool = False
        self.user_interrupted: bool = False
        self.tts_chunk_sent: bool = False
        self.tts_client_playing: bool = False
        self.interruption_time: float = 0.0

        # ì´ê²ƒë“¤ì€ ì´ë¯¸ ì‚¬ì‹¤ìƒ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì´ê±°ë‚˜ ë¦¬ì…‹ ë¡œì§ì´ ì¡´ì¬í–ˆìŒ
        self.silence_active: bool = True
        self.is_hot: bool = False
        self.user_finished_turn: bool = False
        self.synthesis_started: bool = False
        self.assistant_answer: str = ""
        self.final_assistant_answer: str = ""
        self.is_processing_potential: bool = False
        self.is_processing_final: bool = False
        self.last_inferred_transcription: str = ""
        self.final_assistant_answer_sent: bool = False
        self.partial_transcription: str = "" # ëª…í™•ì„±ì„ ìœ„í•´ ì¶”ê°€

        self.reset_state() # ì¼ê´€ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ë¦¬ì…‹ í˜¸ì¶œ

        # AI-to-AI ëŒ€í™”ë¥¼ ìœ„í•œ TTS ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ì¶”ê°€
        self.tts_playback_finished_event = threading.Event()

        self.abort_request_event = threading.Event()
        self.abort_worker_thread = threading.Thread(target=self._abort_worker, name="AbortWorker", daemon=True)
        self.abort_worker_thread.start()


    def on_tts_playback_finished(self):
        """í´ë¼ì´ì–¸íŠ¸ TTS ì¬ìƒ ì™„ë£Œ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°±"""
        logger.info("ğŸ”Š í´ë¼ì´ì–¸íŠ¸ TTS ì¬ìƒ ì™„ë£Œ, AI-to-AI ë‹¤ìŒ í„´ ì‹œì‘ ê°€ëŠ¥")
        self.tts_playback_finished_event.set()
        
    def start_silence_timer_after_tts_stop(self):
        """TTS ì¬ìƒ ì™„ë£Œ í›„ ì¹¨ë¬µ íƒ€ì´ë¨¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        # AI-to-AI ëŒ€í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¹¨ë¬µ íƒ€ì´ë¨¸ ì‹œì‘
        if not self.app.state.SpeechPipelineManager.ai_to_ai_active:
            logger.info("ğŸ–¥ï¸â° TTS ì¬ìƒ ì™„ë£Œë¡œ ì¸í•œ ì¹¨ë¬µ íƒ€ì´ë¨¸ ì‹œì‘")
            self.app.state.AudioInputProcessor.transcriber.start_prolonged_silence_timer()

    def handle_toggle_ai_pause(self):
        """AI ëŒ€í™” ì¼ì‹œì¤‘ì§€/ì¬ê°œë¥¼ ì²˜ë¦¬í•˜ê³  í´ë¼ì´ì–¸íŠ¸ì— ìƒíƒœë¥¼ ì•Œë¦½ë‹ˆë‹¤."""
        is_paused = self.app.state.SpeechPipelineManager.toggle_pause_ai_conversation()
        
        # AI ëŒ€í™” ìƒíƒœì— ë”°ë¼ ì¥ì‹œê°„ ì¹¨ë¬µ íƒ€ì´ë¨¸ë¥¼ ì œì–´í•©ë‹ˆë‹¤.
        if is_paused:
            logger.info("ğŸ¤–â¯ï¸ AI ëŒ€í™”ê°€ ì¼ì‹œì¤‘ì§€ë˜ì–´ ì¥ì‹œê°„ ì¹¨ë¬µ íƒ€ì´ë¨¸ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤.")
            self.app.state.AudioInputProcessor.transcriber.stop_prolonged_silence_timer()
        else:
            logger.info("ğŸ¤–â¯ï¸ AI ëŒ€í™”ê°€ ì¬ê°œë˜ì–´ ì¥ì‹œê°„ ì¹¨ë¬µ íƒ€ì´ë¨¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            self.app.state.AudioInputProcessor.transcriber.start_prolonged_silence_timer()

        self.message_queue.put_nowait({
            "type": "ai_conversation_paused_status",
            "is_paused": is_paused
        })

    def on_ai_turn_start(self):
        """AIì˜ í„´ì´ ì‹œì‘ë  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±."""
        logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ”Š AI í„´ ì‹œì‘, TTS ìŠ¤íŠ¸ë¦¼ í—ˆìš©').blue}")
        self.tts_to_client = True

    def on_tts_all_complete(self):
        """ëª¨ë“  TTS ì²˜ë¦¬ê°€ ì™„ë£Œë  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°± (ë¹ ë¥¸ TTS + ìµœì¢… TTS)"""
        logger.info("ğŸ–¥ï¸ğŸ”Š ëª¨ë“  TTS ì²˜ë¦¬ ì™„ë£Œ, í´ë¼ì´ì–¸íŠ¸ì— ì™„ë£Œ ì‹ í˜¸ ì „ì†¡")
        self.message_queue.put_nowait({
            "type": "tts_all_complete"
        })


    def reset_state(self):
        """ì—°ê²°ë³„ ìƒíƒœ í”Œë˜ê·¸ì™€ ë³€ìˆ˜ë¥¼ ì´ˆê¸° ê°’ìœ¼ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤."""
        # ëª¨ë“  ì—°ê²°ë³„ ìƒíƒœ í”Œë˜ê·¸ ë¦¬ì…‹
        self.tts_to_client = False
        self.user_interrupted = False
        self.tts_chunk_sent = False
        # tts_client_playingì€ í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ë³´ê³ ë¥¼ ë°˜ì˜í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ë¦¬ì…‹í•˜ì§€ ì•ŠìŒ
        self.interruption_time = 0.0

        # ë‹¤ë¥¸ ìƒíƒœ ë³€ìˆ˜ ë¦¬ì…‹
        self.silence_active = True
        self.is_hot = False
        self.user_finished_turn = False
        self.synthesis_started = False
        self.assistant_answer = ""
        self.final_assistant_answer = ""
        self.is_processing_potential = False
        self.is_processing_final = False
        self.last_inferred_transcription = ""
        self.final_assistant_answer_sent = False
        self.partial_transcription = ""

        # ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ/íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ìì™€ ê´€ë ¨ëœ ì¤‘ë‹¨ í˜¸ì¶œ ìœ ì§€
        self.app.state.AudioInputProcessor.abort_generation()


    def _abort_worker(self):
        """ë¶€ë¶„ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë‹¨ ì¡°ê±´ì„ í™•ì¸í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì›Œì»¤."""
        while True:
            was_set = self.abort_request_event.wait(timeout=0.1) # 100msë§ˆë‹¤ í™•ì¸
            if was_set:
                self.abort_request_event.clear()
                # í…ìŠ¤íŠ¸ê°€ ì‹¤ì œë¡œ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¤‘ë‹¨ í™•ì¸ íŠ¸ë¦¬ê±°
                if self.last_abort_text != self.abort_text:
                    self.last_abort_text = self.abort_text
                    logger.debug(f"ğŸ–¥ï¸ğŸ§  ë¶€ë¶„ í…ìŠ¤íŠ¸ë¡œ ì¤‘ë‹¨ í™•ì¸ íŠ¸ë¦¬ê±°ë¨: '{self.abort_text}'")
                    self.app.state.SpeechPipelineManager.check_abort(self.abort_text, False, "on_partial")

    def on_partial(self, txt: str):
        """
        ë¶€ë¶„ ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ë‚´ë¶€ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ , ë¶€ë¶„ ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•˜ë©°,
        ì ì¬ì  ì¤‘ë‹¨ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì¤‘ë‹¨ ì›Œì»¤ ìŠ¤ë ˆë“œì— ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.

        Args:
            txt: ë¶€ë¶„ ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸.
        """
        self.final_assistant_answer_sent = False # ìƒˆë¡œìš´ ì‚¬ìš©ì ë°œí™”ëŠ” ì´ì „ ìµœì¢… ë‹µë³€ ì „ì†¡ ìƒíƒœë¥¼ ë¬´íš¨í™”í•¨
        self.final_transcription = "" # ì´ê²ƒì€ ë¶€ë¶„ì´ë¯€ë¡œ ìµœì¢… ìŒì„± ì¸ì‹ ì§€ìš°ê¸°
        self.partial_transcription = txt
        self.message_queue.put_nowait({"type": "partial_user_request", "content": txt})
        self.abort_text = txt # ì¤‘ë‹¨ í™•ì¸ì— ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        self.abort_request_event.set() # ì¤‘ë‹¨ ì›Œì»¤ì— ì‹ í˜¸ ë³´ë‚´ê¸°

    def safe_abort_running_syntheses(self, reason: str):
        """ì•ˆì „í•˜ê²Œ í•©ì„±ì„ ì¤‘ë‹¨í•˜ê¸° ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë” (í˜„ì¬ ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•ŠìŒ)."""
        # TODO: í•„ìš”í•œ ê²½ìš° ì‹¤ì œ ì¤‘ë‹¨ ë¡œì§ êµ¬í˜„, ì ì¬ì ìœ¼ë¡œ SpeechPipelineManagerì™€ ìƒí˜¸ ì‘ìš©
        pass

    def on_tts_allowed_to_synthesize(self):
        """
        ì‹œìŠ¤í…œì´ TTS í•©ì„±ì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤ê³  íŒë‹¨í•  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        """
        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        if self.app.state.SpeechPipelineManager.running_generation and not self.app.state.SpeechPipelineManager.running_generation.abortion_started:
            # logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ”Š TTS í—ˆìš©ë¨').blue}")
            self.app.state.SpeechPipelineManager.running_generation.tts_quick_allowed_event.set()

    def on_potential_sentence(self, txt: str):
        """
        STTì— ì˜í•´ ì ì¬ì ìœ¼ë¡œ ì™„ì „í•œ ë¬¸ì¥ì´ ê°ì§€ë  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ì´ ì ì¬ì  ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìŒì„± ìƒì„± ì¤€ë¹„ë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.

        Args:
            txt: ì ì¬ì  ë¬¸ì¥ í…ìŠ¤íŠ¸.
        """
        logger.debug(f"ğŸ–¥ï¸ğŸ§  ì ì¬ì  ë¬¸ì¥: '{txt}'")
        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        self.app.state.SpeechPipelineManager.prepare_generation(txt)

    def on_potential_final(self, txt: str):
        """
        ì ì¬ì ì¸ *ìµœì¢…* ìŒì„± ì¸ì‹ì´ ê°ì§€ë  ë•Œ(hot ìƒíƒœ) í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ì ì¬ì  ìµœì¢… ìŒì„± ì¸ì‹ì„ ë¡œê·¸ì— ê¸°ë¡í•©ë‹ˆë‹¤.

        Args:
            txt: ì ì¬ì  ìµœì¢… ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸.
        """
        logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ§  HOT: ').magenta}{txt}")

    def on_potential_abort(self):
        """STTê°€ ì‚¬ìš©ì ë°œí™”ì— ê¸°ë°˜í•œ ì ì¬ì  ì¤‘ë‹¨ í•„ìš”ì„±ì„ ê°ì§€í•˜ë©´ í˜¸ì¶œë˜ëŠ” ì½œë°±."""
        # í”Œë ˆì´ìŠ¤í™€ë”: í˜„ì¬ ì•„ë¬´ê²ƒë„ ë¡œê·¸í•˜ì§€ ì•Šìœ¼ë©°, ì¤‘ë‹¨ ë¡œì§ì„ íŠ¸ë¦¬ê±°í•  ìˆ˜ ìˆìŒ.
        pass

    def on_before_final(self, audio: bytes, txt: str):
        """
        ì‚¬ìš©ì ì°¨ë¡€ì˜ ìµœì¢… STT ê²°ê³¼ê°€ í™•ì •ë˜ê¸° ì§ì „ì— í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ì‚¬ìš©ì ì¢…ë£Œ í”Œë˜ê·¸ë¥¼ ì„¤ì •í•˜ê³ , ë³´ë¥˜ ì¤‘ì¸ ê²½ìš° TTSë¥¼ í—ˆìš©í•˜ë©°, ë§ˆì´í¬ ì…ë ¥ì„ ì¤‘ë‹¨í•˜ê³ ,
        í´ë¼ì´ì–¸íŠ¸ë¡œ TTS ìŠ¤íŠ¸ë¦¼ì„ í•´ì œí•˜ë©°, ìµœì¢… ì‚¬ìš©ì ìš”ì²­ê³¼ ë³´ë¥˜ ì¤‘ì¸ ë¶€ë¶„
        ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•˜ê³ , ì‚¬ìš©ì ìš”ì²­ì„ ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.

        Args:
            audio: ìµœì¢… ìŒì„± ì¸ì‹ì— í•´ë‹¹í•˜ëŠ” ì›ì‹œ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸. (í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨)
            txt: ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸ (on_finalì—ì„œ ì•½ê°„ ì •ì œë  ìˆ˜ ìˆìŒ).
        """
        logger.info(Colors.apply('ğŸ–¥ï¸ğŸ =================== ì‚¬ìš©ì ì°¨ë¡€ ì¢…ë£Œ ===================').light_gray)
        self.user_finished_turn = True
        self.user_interrupted = False # ì—°ê²°ë³„ í”Œë˜ê·¸ ë¦¬ì…‹ (ì‚¬ìš©ì ì¢…ë£Œ, ì¤‘ë‹¨ ì•„ë‹˜)
        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        if self.app.state.SpeechPipelineManager.is_valid_gen():
            logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ”Š TTS í—ˆìš©ë¨ (ìµœì¢… ì „)').blue}")
            self.app.state.SpeechPipelineManager.running_generation.tts_quick_allowed_event.set()

        # ë¨¼ì € ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ ì°¨ë‹¨ (ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œì˜ ìƒíƒœ)
        if not self.app.state.AudioInputProcessor.interrupted:
            logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ™ï¸ â¸ï¸ ë§ˆì´í¬ ì¤‘ë‹¨ë¨ (ì°¨ë¡€ ì¢…ë£Œ)').cyan}")
            self.app.state.AudioInputProcessor.interrupted = True
            self.interruption_time = time.time() # ì—°ê²°ë³„ í”Œë˜ê·¸ ì„¤ì •

        logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ”Š TTS ìŠ¤íŠ¸ë¦¼ í•´ì œë¨').blue}")
        self.tts_to_client = True # ì—°ê²°ë³„ í”Œë˜ê·¸ ì„¤ì •

        # ìµœì¢… ì‚¬ìš©ì ìš”ì²­ ì „ì†¡ (ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” final_transcription ë˜ëŠ” ìµœì¢…ì´ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° í˜„ì¬ ë¶€ë¶„ ì‚¬ìš©)
        user_request_content = self.final_transcription if self.final_transcription else self.partial_transcription
        self.message_queue.put_nowait({
            "type": "final_user_request",
            "content": user_request_content
        })

        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        if self.app.state.SpeechPipelineManager.is_valid_gen():
            # ë¶€ë¶„ ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€(ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
            # ì—°ê²°ë³„ user_interrupted í”Œë˜ê·¸ ì‚¬ìš©
            if self.app.state.SpeechPipelineManager.running_generation.quick_answer and not self.user_interrupted:
                self.assistant_answer = self.app.state.SpeechPipelineManager.running_generation.quick_answer
                
                # í˜„ì¬ ë°œí™”ì ì—­í•  ê°€ì ¸ì˜¤ê¸°
                speaker_role = self.app.state.SpeechPipelineManager.running_generation.speaker_role
                
                self.message_queue.put_nowait({
                    "type": "partial_assistant_answer",
                    "content": self.assistant_answer,
                    "role": speaker_role
                })

        logger.info(f"ğŸ–¥ï¸ğŸ§  ê¸°ë¡ì— ì‚¬ìš©ì ìš”ì²­ ì¶”ê°€ ì¤‘: '{user_request_content}'")
        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        self.app.state.SpeechPipelineManager.history.append({"role": "user", "content": user_request_content})

    def on_final(self, txt: str):
        """
        ì‚¬ìš©ì ì°¨ë¡€ì˜ ìµœì¢… ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ìµœì¢… ìŒì„± ì¸ì‹ì„ ë¡œê·¸ì— ê¸°ë¡í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            txt: ìµœì¢… ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸.
        """
        logger.info(f"\n{Colors.apply('ğŸ–¥ï¸âœ… ìµœì¢… ì‚¬ìš©ì ìš”ì²­ (STT ì½œë°±): ').green}{txt}")
        if not self.final_transcription: # on_before_final ë¡œì§ì—ì„œ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì €ì¥
             self.final_transcription = txt

    def abort_generations(self, reason: str):
        """
        ì§„í–‰ ì¤‘ì¸ ëª¨ë“  ìŒì„± ìƒì„± í”„ë¡œì„¸ìŠ¤ì˜ ì¤‘ë‹¨ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.

        ì´ìœ ë¥¼ ë¡œê·¸ì— ê¸°ë¡í•˜ê³  SpeechPipelineManagerì˜ ì¤‘ë‹¨ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

        Args:
            reason: ì¤‘ë‹¨ì´ íŠ¸ë¦¬ê±°ëœ ì´ìœ ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ìì—´.
        """
        logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ›‘ ìƒì„± ì¤‘ë‹¨:').blue} {reason}")
        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        self.app.state.SpeechPipelineManager.abort_generation(reason=f"server.py abort_generations: {reason}")

    def on_silence_active(self, silence_active: bool):
        """
        ì¹¨ë¬µ ê°ì§€ ìƒíƒœê°€ ë³€ê²½ë  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ë‚´ë¶€ silence_active í”Œë˜ê·¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

        Args:
            silence_active: í˜„ì¬ ì¹¨ë¬µì´ ê°ì§€ë˜ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False.
        """
        # logger.debug(f"ğŸ–¥ï¸ğŸ™ï¸ ì¹¨ë¬µ í™œì„±: {silence_active}") # ì„ íƒ ì‚¬í•­: ì‹œë„ëŸ¬ìš¸ ìˆ˜ ìˆìŒ
        self.silence_active = silence_active

    def on_partial_assistant_text(self, txt: str):
        """
        ì–´ì‹œìŠ¤í„´íŠ¸(LLM)ë¡œë¶€í„° ë¶€ë¶„ í…ìŠ¤íŠ¸ ê²°ê³¼ê°€ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        ë‚´ë¶€ ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ , ì‚¬ìš©ìê°€ ì¤‘ë‹¨í•˜ì§€ ì•Šì€ í•œ
        ë¶€ë¶„ ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

        Args:
            txt: ë¶€ë¶„ ì–´ì‹œìŠ¤í„´íŠ¸ í…ìŠ¤íŠ¸.
        """
        # logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ’¬ ë¶€ë¶„ ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€: ').green}{txt}")
        # ì—°ê²°ë³„ user_interrupted í”Œë˜ê·¸ ì‚¬ìš©
        if not self.user_interrupted:
            self.assistant_answer = txt
            # ì—°ê²°ë³„ tts_to_client í”Œë˜ê·¸ ì‚¬ìš©
            if self.tts_to_client:
                # í˜„ì¬ ë°œí™”ì ì—­í•  ê°€ì ¸ì˜¤ê¸°
                speaker_role = "assistant" # ê¸°ë³¸ê°’
                if self.app.state.SpeechPipelineManager.is_valid_gen():
                    speaker_role = self.app.state.SpeechPipelineManager.running_generation.speaker_role

                self.message_queue.put_nowait({
                    "type": "partial_assistant_answer",
                    "content": txt,
                    "role": speaker_role
                })

    def on_recording_start(self):
        """
        ì˜¤ë””ì˜¤ ì…ë ¥ í”„ë¡œì„¸ì„œê°€ ì‚¬ìš©ì ìŒì„± ë…¹ìŒì„ ì‹œì‘í•  ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.

        í´ë¼ì´ì–¸íŠ¸ ì¸¡ TTSê°€ ì¬ìƒ ì¤‘ì¸ ê²½ìš° ì¤‘ë‹¨ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤: ì„œë²„ ì¸¡
        TTS ìŠ¤íŠ¸ë¦¬ë°ì„ ì¤‘ì§€í•˜ê³ , í´ë¼ì´ì–¸íŠ¸ì— ì¤‘ì§€/ì¤‘ë‹¨ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³ , ì§„í–‰ ì¤‘ì¸
        ìƒì„±ì„ ì¤‘ë‹¨í•˜ê³ , ì§€ê¸ˆê¹Œì§€ ìƒì„±ëœ ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì„ ë³´ë‚´ê³ , ê´€ë ¨ ìƒíƒœë¥¼
        ë¦¬ì…‹í•©ë‹ˆë‹¤.
        """
        logger.info(f"{Colors.ORANGE}ğŸ–¥ï¸ğŸ™ï¸ ë…¹ìŒ ì‹œì‘ë¨.{Colors.RESET} TTS í´ë¼ì´ì–¸íŠ¸ ì¬ìƒ ì¤‘: {self.tts_client_playing}")
        # ì—°ê²°ë³„ tts_client_playing í”Œë˜ê·¸ ì‚¬ìš©
        if self.tts_client_playing:
            self.tts_to_client = False # ì„œë²„ê°€ TTS ì „ì†¡ ì¤‘ì§€
            self.user_interrupted = True # ì—°ê²°ì„ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í•œ ê²ƒìœ¼ë¡œ í‘œì‹œ
            logger.info(f"{Colors.apply('ğŸ–¥ï¸â— ë…¹ìŒ ì‹œì‘ìœ¼ë¡œ ì¸í•œ TTS ì¤‘ë‹¨').blue}")

            # ìƒì„±ë˜ì—ˆê³  ì „ì†¡ë˜ì§€ ì•Šì€ ê²½ìš° ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ ì „ì†¡
            logger.info(Colors.apply("ğŸ–¥ï¸âœ… ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ ì „ì†¡ (ì¤‘ë‹¨ ì‹œ ê°•ì œ)").pink)
            self.send_final_assistant_answer(forced=True)

            # ì¤‘ë‹¨ì„ ìœ„í•œ ìµœì†Œí•œì˜ ë¦¬ì…‹:
            self.tts_chunk_sent = False # ì²­í¬ ì „ì†¡ í”Œë˜ê·¸ ë¦¬ì…‹
            # self.assistant_answer = "" # ì„ íƒ ì‚¬í•­: í•„ìš”í•œ ê²½ìš° ë¶€ë¶„ ë‹µë³€ ì§€ìš°ê¸°

            logger.info("ğŸ–¥ï¸ğŸ›‘ í´ë¼ì´ì–¸íŠ¸ì— stop_tts ì „ì†¡ ì¤‘.")
            self.message_queue.put_nowait({
                "type": "stop_tts", # í´ë¼ì´ì–¸íŠ¸ê°€ ì´ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìŒì†Œê±°/ë¬´ì‹œ
                "content": ""
            })

            logger.info(f"{Colors.apply('ğŸ–¥ï¸ğŸ›‘ ë…¹ìŒ ì‹œì‘ìœ¼ë¡œ ìƒì„± ì¤‘ë‹¨').red}")
            self.abort_generations("on_recording_start, user interrupts, TTS Playing")

            logger.info("ğŸ–¥ï¸â— í´ë¼ì´ì–¸íŠ¸ì— tts_interruption ì „ì†¡ ì¤‘.")
            self.message_queue.put_nowait({ # í´ë¼ì´ì–¸íŠ¸ì— ì¬ìƒ ì¤‘ì§€ ë° ë²„í¼ ë¹„ìš°ê¸° ì§€ì‹œ
                "type": "tts_interruption",
                "content": ""
            })

            # ì´ì „ ìƒíƒœì— ê¸°ë°˜í•œ ì‘ì—… ìˆ˜í–‰ *í›„* ìƒíƒœ ë¦¬ì…‹
            # ì •í™•íˆ ë¬´ì—‡ì„ ë¦¬ì…‹í•˜ê³  ë¬´ì—‡ì„ ìœ ì§€í•´ì•¼ í•˜ëŠ”ì§€ ì£¼ì˜ (tts_client_playing ë“±)
            # self.reset_state() # ë„ˆë¬´ ë§ì´ ì§€ìš¸ ìˆ˜ ìˆìŒ, ì˜ˆë¥¼ ë“¤ì–´ user_interruptedë¥¼ ì¡°ê¸°ì—

    def send_final_assistant_answer(self, forced=False, speaker_role_override=None):
        """
        ìµœì¢… (ë˜ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ìµœìƒì˜) ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

        ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ë¹ ë¥¸ ë‹µë³€ê³¼ ìµœì¢… ë‹µë³€ ë¶€ë¶„ì—ì„œ ì „ì²´ ë‹µë³€ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
        `forced`ì´ê³  ì „ì²´ ë‹µë³€ì´ ì—†ëŠ” ê²½ìš° ë§ˆì§€ë§‰ ë¶€ë¶„ ë‹µë³€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ê³  ì•„ì§ ì „ì†¡ë˜ì§€ ì•Šì€ ê²½ìš° 'final_assistant_answer'ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

        Args:
            forced: Trueì¸ ê²½ìš°, ì™„ì „í•œ ìµœì¢… ë‹µë³€ì´ ì—†ì„ ë•Œ ë§ˆì§€ë§‰ ë¶€ë¶„ ë‹µë³€ì„
                    ì „ì†¡í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ False.
            speaker_role_override: AI-to-AI ëŒ€í™”ì™€ ê°™ì´ ì—­í• ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        """
        final_answer = ""
        # ì „ì—­ ê´€ë¦¬ì ìƒíƒœ ì ‘ê·¼
        if self.app.state.SpeechPipelineManager.is_valid_gen():
            final_answer = self.app.state.SpeechPipelineManager.running_generation.quick_answer + self.app.state.SpeechPipelineManager.running_generation.final_answer

        if not final_answer: # êµ¬ì„±ëœ ë‹µë³€ì´ ë¹„ì–´ ìˆëŠ”ì§€ í™•ì¸
            # ê°•ì œëœ ê²½ìš°, ì´ ì—°ê²°ì˜ ë§ˆì§€ë§‰ìœ¼ë¡œ ì•Œë ¤ì§„ ë¶€ë¶„ ë‹µë³€ ì‚¬ìš© ì‹œë„
            if forced and self.assistant_answer:
                 final_answer = self.assistant_answer
                 logger.warning(f"ğŸ–¥ï¸âš ï¸ ë¶€ë¶„ ë‹µë³€ì„ ìµœì¢…ìœ¼ë¡œ ì‚¬ìš© (ê°•ì œ): '{final_answer}'")
            else:
                logger.warning(f"ğŸ–¥ï¸âš ï¸ ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì´ ë¹„ì–´ ìˆì–´ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                # if self.app.state.SpeechPipelineManager.is_valid_gen():
                #     self.app.state.SpeechPipelineManager.running_generation.turn_finished_event.set()
                return# ë³´ë‚¼ ê²ƒì´ ì—†ìŒ

        logger.debug(f"ğŸ–¥ï¸âœ… ìµœì¢… ë‹µë³€ ì „ì†¡ ì‹œë„: '{final_answer}' (ì´ì „ì— ì „ì†¡ë¨: {self.final_assistant_answer_sent})")

        if not self.final_assistant_answer_sent and final_answer:
            import re
            # ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_answer = re.sub(r'[\r\n]+', ' ', final_answer)
            cleaned_answer = re.sub(r'\s+', ' ', cleaned_answer).strip()
            cleaned_answer = cleaned_answer.replace('\\n', ' ')
            cleaned_answer = re.sub(r'\s+', ' ', cleaned_answer).strip()

            if cleaned_answer: # ì •ë¦¬ í›„ ë¹„ì–´ ìˆì§€ ì•Šì€ì§€ í™•ì¸
                logger.info(f"\n{Colors.apply('ğŸ–¥ï¸âœ… ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ (ì „ì†¡ ì¤‘): ').green}{cleaned_answer}")
                
                # í˜„ì¬ ë°œí™”ì ì—­í•  ê°€ì ¸ì˜¤ê¸°
                speaker_role = speaker_role_override or "assistant" # ì˜¤ë²„ë¼ì´ë“œ ì‚¬ìš© ë˜ëŠ” ê¸°ë³¸ê°’
                if not speaker_role_override and self.app.state.SpeechPipelineManager.is_valid_gen():
                    speaker_role = self.app.state.SpeechPipelineManager.running_generation.speaker_role

                self.message_queue.put_nowait({
                    "type": "final_assistant_answer",
                    "content": cleaned_answer,
                    "role": speaker_role 
                })
                self.app.state.SpeechPipelineManager.history.append({"role": speaker_role, "content": cleaned_answer})
                self.final_assistant_answer_sent = True
                self.final_assistant_answer = cleaned_answer # ì „ì†¡ëœ ë‹µë³€ ì €ì¥
            else:
                logger.warning(f"ğŸ–¥ï¸âš ï¸ {Colors.YELLOW}ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì´ ì •ë¦¬ í›„ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.{Colors.RESET}")
                self.final_assistant_answer_sent = False # ì „ì†¡ë¨ìœ¼ë¡œ í‘œì‹œ ì•ˆ í•¨
                self.final_assistant_answer = "" # ì €ì¥ëœ ë‹µë³€ ì§€ìš°ê¸°
        elif forced and not final_answer: # ì´ì „ í™•ì¸ìœ¼ë¡œ ì¸í•´ ë°œìƒí•´ì„œëŠ” ì•ˆ ë˜ì§€ë§Œ, ì•ˆì „ì„ ìœ„í•´
             logger.warning(f"ğŸ–¥ï¸âš ï¸ {Colors.YELLOW}ìµœì¢… ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì˜ ê°•ì œ ì „ì†¡, í•˜ì§€ë§Œ ë¹„ì–´ ìˆì—ˆìŠµë‹ˆë‹¤.{Colors.RESET}")
             self.final_assistant_answer = "" # ì €ì¥ëœ ë‹µë³€ ì§€ìš°ê¸°
        
        # if self.app.state.SpeechPipelineManager.is_valid_gen():
        #     self.app.state.SpeechPipelineManager.running_generation.turn_finished_event.set()


# --------------------------------------------------------------------
# ë©”ì¸ ì›¹ì†Œì¼“ ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------------------------
@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    """
    ì‹¤ì‹œê°„ ìŒì„± ì±„íŒ…ì„ ìœ„í•œ ë©”ì¸ ì›¹ì†Œì¼“ ì—°ê²°ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    ì—°ê²°ì„ ìˆ˜ë½í•˜ê³ , `TranscriptionCallbacks`ë¥¼ í†µí•´ ì—°ê²°ë³„ ìƒíƒœë¥¼ ì„¤ì •í•˜ê³ ,
    ì˜¤ë””ì˜¤/ë©”ì‹œì§€ íë¥¼ ì´ˆê¸°í™”í•˜ë©°, ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°, ì˜¤ë””ì˜¤ ì²˜ë¦¬, ë‚˜ê°€ëŠ” í…ìŠ¤íŠ¸ ë©”ì‹œì§€,
    ë‚˜ê°€ëŠ” TTS ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ asyncio ì‘ì—…ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ëŸ¬í•œ ì‘ì—…ì˜ ìˆ˜ëª… ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ê³  ì—°ê²° ëŠê¹€ ì‹œ ì •ë¦¬í•©ë‹ˆë‹¤.

    Args:
        ws: FastAPIì—ì„œ ì œê³µí•˜ëŠ” ì›¹ì†Œì¼“ ì—°ê²° ì¸ìŠ¤í„´ìŠ¤.
    """
    await ws.accept()
    logger.info("ğŸ–¥ï¸âœ… í´ë¼ì´ì–¸íŠ¸ê°€ ì›¹ì†Œì¼“ì„ í†µí•´ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
    app.state.SpeechPipelineManager.set_client_connection_status(True)

    message_queue = asyncio.Queue()
    audio_chunks = asyncio.Queue()

    # ì½œë°± ê´€ë¦¬ì ì„¤ì • - ì´ê²ƒì´ ì´ì œ ì—°ê²°ë³„ ìƒíƒœë¥¼ ë³´ìœ í•¨
    callbacks = TranscriptionCallbacks(app, message_queue)

    # AudioInputProcessor(ì „ì—­ ì»´í¬ë„ŒíŠ¸)ì— ì½œë°± í• ë‹¹
    # callbacks ë‚´ì˜ ì´ ë©”ì„œë“œë“¤ì€ ì´ì œ í•´ë‹¹ *ì¸ìŠ¤í„´ìŠ¤* ìƒíƒœì—ì„œ ì‘ë™í•¨
    app.state.AudioInputProcessor.realtime_callback = callbacks.on_partial
    app.state.AudioInputProcessor.transcriber.potential_sentence_end = callbacks.on_potential_sentence
    app.state.AudioInputProcessor.transcriber.on_tts_allowed_to_synthesize = callbacks.on_tts_allowed_to_synthesize
    app.state.AudioInputProcessor.transcriber.potential_full_transcription_callback = callbacks.on_potential_final
    app.state.AudioInputProcessor.transcriber.potential_full_transcription_abort_callback = callbacks.on_potential_abort
    app.state.AudioInputProcessor.transcriber.full_transcription_callback = callbacks.on_final
    app.state.AudioInputProcessor.transcriber.before_final_sentence = callbacks.on_before_final
    app.state.AudioInputProcessor.recording_start_callback = callbacks.on_recording_start
    app.state.AudioInputProcessor.silence_active_callback = callbacks.on_silence_active

    # SpeechPipelineManager(ì „ì—­ ì»´í¬ë„ŒíŠ¸)ì— ì½œë°± í• ë‹¹
    app.state.SpeechPipelineManager.on_partial_assistant_text = callbacks.on_partial_assistant_text
    app.state.SpeechPipelineManager.on_final_assistant_answer = callbacks.send_final_assistant_answer
    app.state.SpeechPipelineManager.on_ai_turn_start = callbacks.on_ai_turn_start
    app.state.SpeechPipelineManager.on_tts_all_complete = callbacks.on_tts_all_complete
    
    # AI-to-AI ëŒ€í™”ë¥¼ ìœ„í•œ TTS ì¬ìƒ ì™„ë£Œ ì½œë°± ì—°ê²°
    app.state.SpeechPipelineManager.tts_playback_finished_callback = callbacks

    # ë‹¤ë¥¸ ì±…ì„ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì‘ì—… ìƒì„±
    # ì—°ê²°ë³„ ìƒíƒœê°€ í•„ìš”í•œ ì‘ì—…ì— 'callbacks' ì¸ìŠ¤í„´ìŠ¤ ì „ë‹¬
    tasks = [
        asyncio.create_task(process_incoming_data(ws, app, audio_chunks, callbacks)), # callbacks ì „ë‹¬
        asyncio.create_task(app.state.AudioInputProcessor.process_chunk_queue(audio_chunks)),
        asyncio.create_task(send_text_messages(ws, message_queue)),
        asyncio.create_task(send_tts_chunks(app, message_queue, callbacks)), # callbacks ì „ë‹¬
    ]

    try:
        # ì‘ì—… ì¤‘ í•˜ë‚˜ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ì˜ˆ: í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€)
        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
        for task in pending:
            if not task.done():
                task.cancel()
        # í•„ìš”í•œ ê²½ìš° ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì·¨ì†Œëœ ì‘ì—… ëŒ€ê¸°
        await asyncio.gather(*pending, return_exceptions=True)
    except Exception as e:
        logger.error(f"ğŸ–¥ï¸ğŸ’¥ {Colors.apply('ì˜¤ë¥˜').red} ì›¹ì†Œì¼“ ì„¸ì…˜ì—ì„œ ë°œìƒ: {repr(e)}")
    finally:
        logger.info("ğŸ–¥ï¸ğŸ§¹ ì›¹ì†Œì¼“ ì‘ì—… ì •ë¦¬ ì¤‘...")
        
        # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸ (ì—°ê²° ëŠê¹€)
        app.state.SpeechPipelineManager.set_client_connection_status(False)
        
        for task in tasks:
            if not task.done():
                task.cancel()
        # ì·¨ì†Œ í›„ ëª¨ë“  ì‘ì—…ì´ ëŒ€ê¸°ë˜ë„ë¡ ë³´ì¥
        # ì •ë¦¬ ì¤‘ ì²« ì˜¤ë¥˜ì—ì„œ gatherê°€ ë©ˆì¶”ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ return_exceptions=True ì‚¬ìš©
        await asyncio.gather(*tasks, return_exceptions=True)
        logger.info("ğŸ–¥ï¸âŒ ì›¹ì†Œì¼“ ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# --------------------------------------------------------------------
# ì§„ì…ì 
# --------------------------------------------------------------------
if __name__ == "__main__":

    # SSL ì—†ì´ ì„œë²„ ì‹¤í–‰
    if not USE_SSL:
        logger.info("ğŸ–¥ï¸â–¶ï¸ SSL ì—†ì´ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        uvicorn.run("server:app", host="0.0.0.0", port=8000, log_config=None)

    else:
        logger.info("ğŸ–¥ï¸ğŸ”’ SSLë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.")
        # ì¸ì¦ì„œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        cert_file = "1.pem"
        key_file = "1-key.pem"
        if not os.path.exists(cert_file) or not os.path.exists(key_file):
             logger.error(f"ğŸ–¥ï¸ğŸ’¥ SSL ì¸ì¦ì„œ íŒŒì¼({cert_file}) ë˜ëŠ” í‚¤ íŒŒì¼({key_file})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
             logger.error("ğŸ–¥ï¸ğŸ’¥ mkcertë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”:")
             logger.error("ğŸ–¥ï¸ğŸ’¥   choco install mkcert") # ì´ì „ í™•ì¸ì— ê¸°ë°˜í•œ Windows ê°€ì •, í•„ìš” ì‹œ ì¡°ì •
             logger.error("ğŸ–¥ï¸ğŸ’¥   mkcert -install")
             logger.error("ğŸ–¥ï¸ğŸ’¥   mkcert 127.0.0.1 YOUR_LOCAL_IP") # í•„ìš”í•œ ê²½ìš° ì‹¤ì œ IPë¡œ êµì²´í•˜ë„ë¡ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
             logger.error("ğŸ–¥ï¸ğŸ’¥ ì¢…ë£Œí•©ë‹ˆë‹¤.")
             sys.exit(1)

        # SSLë¡œ ì„œë²„ ì‹¤í–‰
        logger.info(f"ğŸ–¥ï¸â–¶ï¸ SSLë¡œ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ì¸ì¦ì„œ: {cert_file}, í‚¤: {key_file}).")
        uvicorn.run(
            "server:app",
            host="0.0.0.0",
            port=8000,
            log_config=None,
            ssl_certfile=cert_file,
            ssl_keyfile=key_file,
        )